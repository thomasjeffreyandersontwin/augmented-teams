---
description: Framework-agnostic BDD testing practices
globs: ["**/*test*.py", "**/*test*.js", "**/*test*.ts", "**/*test*.jsx", "**/*test*.tsx", "**/*spec*.py", "**/*spec*.js", "**/*spec*.ts", "**/*spec*.jsx", "**/*spec*.tsx", "**/*_test.py", "**/test_*.py"]
alwaysApply: false
---
**When** writing Behavior-Driven Development (BDD) tests,
**then** follow these five core principles to ensure tests are readable, maintainable, and focused on observable behavior.

BDD tests should be written in plain language that business stakeholders can understand, comprehensively cover behaviors without being overly broad, balance shared context with test localization, cover all layers of the system appropriately, and focus on user-visible behavior for front-end tests.

**Executing Commands:**
* `/bdd-validate` — Validate BDD test files against these principles
* `/bdd-workflow` — Execute BDD workflow phases (Domain Scaffold, Signatures, Write Tests, Write Code)

## Conventions

Naming conventions, file locations, and structural conventions for BDD tests (what the rules apply to, not the rule files themselves). These conventions are framework-agnostic and apply to all BDD tests regardless of testing framework.

* Describe block naming: Use nouns for describe blocks (domain concepts, states) - e.g., "Character", "Attack that has been created"
* Test block naming: Start with "should" followed by behavior description - e.g., "should have initial stats"
* Hierarchy structure: Nest from broad to specific contexts, each child adds context to parent
* Scaffold file naming: Use `{test-file-stem}-hierarchy.txt` for plain English scaffold hierarchies
* Domain map file location: Domain maps are typically found in a `docs/` folder (e.g., `docs/*domain-map*.txt`) or in the root directory with the pattern `*domain-map*.txt`

**Note:** Framework-specific conventions (test file naming patterns, file locations, framework syntax) belong in specialized rules, not in the base rule.

## 1. Business Readable Language

Use plain English that business stakeholders can understand. Write test names so that inner/outer sentences create natural sentences. Use nouns for describe blocks (concepts, states). Start each test with "should …". Nest from broad → specific; each child adds context. Use plain behavioral language. Prefer domain terms over technical jargon.

**Especially important during scaffolding and signature creation:** When generating plain English hierarchies (scaffolding) or test signatures, these principles are critical. Scaffolding must use plain English only with NO code syntax (`()`, `=>`, `{}`). Test signatures should follow natural sentence structure that reads aloud clearly.

**[DO]:**
* Use domain language that business stakeholders understand
* Start test names with "should" to describe expected behavior
* Use nouns for describe blocks (concepts, states)
* Nest from broad to specific contexts
* Create natural sentences when combining describe/it blocks
* Connect base business concepts to more specific concepts using linking words like "that is", "that has", "that has been"
* Write in plain English that reads naturally when spoken aloud (especially important for scaffolding)

**[DON'T]:**
* Use technical jargon or implementation details
* Omit "should" from test names
* Use verbs for describe blocks
* Flatten hierarchy unnecessarily
* Use technical class names or method names
* Use implementation-focused language or framework internals in test names
* Use code syntax (`()`, `=>`, `{}`) in scaffolding or test signatures

## 2. Fluency, Hierarchy, and Storytelling

Tests tell stories, not document APIs. Structure test hierarchies to reflect domain concepts and their relationships. Use natural language that flows when read aloud. Preserve domain map hierarchy structure when scaffolding tests.

**Core Principle:** Tests Tell Stories, Not Document APIs

Tests should read like stories about domain concepts, not technical documentation. Each test describes what happens when a user or system interacts with a domain concept under specific conditions.

**Hierarchy Patterns:**

* **Concept Lifecycle Pattern:** Structure tests to follow the natural lifecycle of domain concepts (creation → modification → usage → completion)
  * Example: "Character" → "Character that has been created" → "Character that has been created should have initial stats"
  * Example: "Game" → "Game that is being played" → "Game that is being played should have player actions tracked"
  * When domain interaction files (`*-domain-interactions.txt`) are present, you can leverage scenario order to enhance test ordering (scenarios provide correct storytelling sequence)

* **State Variations with Context Pattern:** Group related state variations under their parent concept
  * Example: "Attack" → "Attack that has been created" → "Attack that has been created should have damage range validated"
  * Example: "Attack" → "Attack that is being executed" → 
    * `describe` block: "Attack that is being executed"
    * `it` block: "should have one dice rolled"

* **Behavioral Relationships Pattern:** Organize tests to show how concepts relate to each other through behaviors
  * Example: "Character" → "Character that is attacking" → "Character that is attacking should have equipped weapon used"
  * Example: "Power" → "Power that is being converted to attack" → "Power that has been converted to attack should have damage values preserved"
  * When domain interaction files (`*-domain-interactions.txt`) are present, you can leverage flow steps to enhance test sequence (flow shows order of domain concept interactions) and use actors to enhance concept relationships (actors identify co-testing opportunities)

**Natural Language Fluency:**

* **Read-Aloud Test:** Test names should read naturally when spoken aloud
  * ✅ "Character that has been created should have initial stats"
  * ❌ "Character created should have initial stats" (missing linking words)
  * ✅ `describe` block: "Attack that is being executed"
    * ✅ `it` block: "should have one dice rolled"
  * ❌ "Attack execution should roll dice" (too technical, action-oriented)

* **Subject Clarity:** Every test should have a clear subject (the domain concept being tested)
  * ✅ "Character that has been created should have initial stats" (subject: Character)
  * ❌ "Should have initial stats" (missing subject)

**Anti-Patterns:**

* **Missing Subject:** Test names that lack a clear subject
  * ❌ "Should validate input" → ✅ "Form that is being submitted should have input validated"
  * ❌ "Should return error" → ✅ "API request that has invalid data should have error returned"

* **Function/Module Names as Describes:** Using technical names instead of domain concepts
  * ❌ "PowerItem" → ✅ "Power"
  * ❌ "getUserSession()" → ✅ "User session that is being retrieved"

* **Disconnected Siblings:** Describe blocks at the same level that are unrelated
  * ❌ "Character" and "DatabaseConnection" (unrelated concepts)
  * ✅ "Character" and "Monster" (related domain concepts)

**Domain Map → Test Hierarchy Mapping:**

When scaffolding tests from domain maps, preserve the domain map hierarchy structure. Map domain concepts to test structure:

* **Domain Concept** → `describe` block (noun, e.g., "Character", "Attack", "Power")
* **Domain State** → `describe` block with linking words (e.g., "Character that has been created", "Attack that is being executed", "User session that is being retrieved")
  * **CRITICAL**: Every `describe` block (especially state blocks with "that" statements) MUST have at least one `it` statement
  * **Acceptable state patterns:**
    * "that has been [past participle]" - completed states (e.g., "that has been created", "that has been saved")
    * "that is being [verb]" - ongoing states (e.g., "that is being retrieved", "that is being executed", "that is being converted", "that is using")
    * "that is [adjective/noun]" - current states (e.g., "that is active", "that is in combat")
    * "that has [noun]" - possession states (e.g., "that has invalid data")
* **Domain Behavior** → `it` block (e.g., "should have initial stats", "should extract epic names", "should create folders")
  * **CRITICAL**: Every `describe` block MUST have at least one `it` block as a child
  * **Valid test name patterns:**
    * ✅ "should [verb]" (e.g., "should extract", "should create", "should validate")
    * ✅ "should [verb] [noun]" (e.g., "should calculate damage", "should select weapon", "should display count")
    * ✅ "should have [noun] [past participle]" (e.g., "should have damage calculated", "should have dice rolled")
    * ✅ "should be [state]" (e.g., "should be active", "should be valid")
    * ✅ "should have [noun]" (e.g., "should have initial stats", "should have error returned")
* **Domain Sub-Concept** → nested `describe` block (preserve nesting depth)

When domain interaction files (`*-domain-interactions.txt`) are present, you can leverage them to enhance the mapping:
* **Business Rules** → `it` blocks (each rule becomes a test case verifying domain constraint)
* **Transformations** → function hints for `it` blocks (transformations tell you what object functions will be)
* **Lookups** → behavior descriptions for `it` blocks (lookup patterns inform what behaviors to test)

Domain map provides primary structure; domain interactions enhance with sequencing and function hints when present.

**CRITICAL: Preserve Domain Map Hierarchy - DO NOT FLATTEN**

When scaffolding from domain maps:
* Maintain the same nesting depth as the domain map
* Preserve parent-child relationships between concepts
* Map each domain concept level to a corresponding describe block level
* Do not collapse multiple levels into a single level

When domain interaction files (`*-domain-interactions.txt`) are present, you can leverage them to enhance:
* Preserve scenario ordering (scenarios provide correct storytelling sequence)
* Preserve flow sequence (flow steps show order of domain concept interactions)
* Ensure business rule coverage (each rule has corresponding `it` block)

**Example Domain Map Structure:**
```
Character
  Creation
    Initial Stats
    Validation Rules
  Combat
    Attacking
      Weapon Selection
      Damage Calculation
    Defending
      Armor Calculation
```

**Corresponding Test Hierarchy (preserving depth):**
```
describe Character
  describe Character that has been created
    it should have initial stats
    it should have required fields validated
  describe Character that is in combat
    describe Character that is attacking
      describe Character that is attacking with weapon
        it should have weapon selected
        it should have damage calculated
    describe Character that is defending
      it should have armor protection calculated
```

Note: Scaffolding output includes both `describe` blocks (for hierarchy/states) and `it` statements (for test cases). This shows the complete test structure.

**Example: Domain Interactions Enhance Scaffolding**

When domain interaction files are present, they enhance the scaffold with sequencing and function hints:

**Domain Map Structure:**
```
Validation
  Rule Selection
  Example Extraction
```

**Domain Interaction Scenario:**
```
SCENARIO 1: VALIDATE TEST FILE

ACTORS:
- Specializing Behavior
- Code-Directed AI Validation
- BDD Validation Command

FLOW:
1. User invokes BDD validation command
2. BDD Validation Runner uses Specializing Behavior
   → Specializing Behavior.Selects Specialized Rule
3. BDD Validation Runner uses Code-Directed AI Validation
   → Code-Directed AI Validation.Extracts Practice Examples

BUSINESS RULES:
- Rule selection through file pattern matching
- DO/DON'T example extraction from rules
- Checklist generation from rule sections
```

**Enhanced Scaffold Hierarchy (with domain interactions):**
```
Validation
  Validation that has been invoked
    Scenario 1: Test File Validation (scenario order determines test ordering)
      Validation that has been invoked with BDD Validation Command
        Validation that is using Specializing Behavior (flow sequence determines test order)
          it should have selected specialized rule through file pattern matching (business rule → it block)
          it should have extracted examples from specialized rule (transformation function hint)
        Validation that is using Code-Directed AI Validation (flow sequence)
          it should have extracted practice examples from DO/DON'T blocks (transformation function hint)
          it should have generated checklist from rule sections (lookup behavior description)
      Validation that involves Specializing Behavior, Code-Directed AI Validation, BDD Validation Command (actors identify relationships)
```

**Key Enhancements from Domain Interactions:**
- **Scenario ordering**: "Scenario 1: Test File Validation" determines test grouping and order
  * **Preferred**: Convert scenario names to state-oriented describe blocks when possible (e.g., "VALIDATE TEST FILE" → "Validation that is validating test file")
  * **Acceptable fallback**: "Scenario N: [Description]" format is acceptable when constructing good state-oriented language is difficult (e.g., "Scenario 1: Test File Validation", "Scenario 2: Rule Selection")
  * **Rule**: Always prefer state-oriented language, but use "Scenario N:" format as a practical fallback when needed
- **Flow sequence**: Flow steps determine test sequence within describe blocks (e.g., "using Specializing Behavior" comes before "using Code-Directed AI Validation")
- **Business rules**: Each rule becomes an `it` block describing state (e.g., "Rule selection through file pattern matching" → `it should have selected specialized rule through file pattern matching`)
- **Transformations**: "Extracts Practice Examples" provides function hint for `it` block description (state-oriented: "should have extracted")
- **Lookups**: "Generates checklist from rule sections" informs behavior description (state-oriented: "should have generated")
- **Actors**: List of actors identifies which concepts should be tested together (state-oriented: "Validation that involves...")

## 3. Comprehensive and Brief Coverage

Cover all behaviors but keep tests focused. Test observable behavior, not hidden internals. Cover state, validation, rules, and interactions. Cover normal, edge, and failure paths. Keep tests short, expressive, readable. Keep tests independent, deterministic, and fast.

**[DO]:**
* Write focused tests for each distinct behavior
* Test observable outcomes, not internal implementation
* Cover normal, edge, and failure cases
* Keep tests independent and deterministic
* Make tests fast and readable
* Cover state, validation, rules, and interactions comprehensively

**[DON'T]:**
* Write overly broad tests that cover multiple behaviors
* Test internal implementation details
* Assert on framework internals or mock internals
* Create tests that depend on execution order
* Write slow or flaky tests
* Test hidden internals or private methods

## 4. Balance Context Sharing with Localization

Extract common setup to shared context (beforeEach/before.each), but keep tests readable. Nest parent context, don't repeat it. Provide expected data via helper factories/builders. Extract complex logic into helpers. Reuse helpers/factories where possible.

**[DO]:**
* Extract common setup to beforeEach/before.each blocks
* Use helper factories for creating test data
* Nest contexts to avoid repetition
* Extract complex setup logic into helper functions
* Balance shared context with test-specific setup
* Provide expected data via helper factories/builders

**[DON'T]:**
* Duplicate setup code across multiple tests
* Repeat parent context setup unnecessarily
* Create overly complex setup in individual tests
* Mix shared and test-specific setup without clear separation
* Create tests that are hard to read due to excessive sharing
* Force shared setup when framework doesn't support it (use helper functions instead)

## 5. Cover All Layers of the System

Test front-end, business logic, and data layers appropriately. Include separate front end, business logic, integration, and data access tests. Isolate across architecture boundaries with mocks and stubs.

**[DO]:**
* Write separate tests for each architectural layer
* Use mocks and stubs to isolate layers
* Test business logic independently of data access
* Test front-end independently of backend services
* Create integration tests for cross-layer behavior

**[DON'T]:**
* Mix concerns from different layers in the same test
* Test dependencies instead of the code under test
* Create tests that require multiple layers to be running
* Skip testing important layers
* Over-mock to the point where tests don't verify real behavior

## 6. Unit Tests the Front-End

Front-end tests should focus on user interactions, not implementation. Mock services, business logic, and routing. Stub user events and verify resulting state or view. Test user-visible behavior, not internal component state or methods.

**[DO]:**
* Test user-visible behavior and interactions
* Mock backend services and business logic
* Verify user-facing outcomes
* Test component behavior from user perspective
* Focus on what users see and do
* Stub user events and verify resulting state or view

**[DON'T]:**
* Test internal component state or methods
* Assert on implementation details
* Test framework internals
* Access component internals directly
* Test what users can't see
* Make real HTTP requests in unit tests
* Assert on HTML rendering details or CSS styling

## 7. Principles Especially Important for Scaffolding and Signature Creation

These principles apply throughout all BDD stages, but are especially critical during scaffolding (plain English hierarchy generation) and signature creation (test structure definition).

**Scaffolding-Specific Requirements:**

* **Plain English with Test Structure Keywords** ⚠️ **Scaffolding Only**
  * Scaffolding output must include `describe` blocks and `it` statements to show the complete test structure
  * Scaffolding uses plain English for test names and descriptions (no function calls, arrow functions, or complex syntax)
  * **CRITICAL REQUIREMENT**: Every `describe` block MUST have at least one `it` statement
    * ✅ `describe Character that has been created` → `it should have initial stats` (has it statement)
    * ❌ `describe Character that has been created` (missing it statement - FORBIDDEN)
    * **Especially important**: `describe` blocks with "that" statements (state blocks) MUST have at least one `it` statement
    * Example: ✅ `describe Character` → `describe Character that has been created` → `it should have initial stats`
    * Example: ❌ `describe Character` → `describe Character that has been created` (no it statement - INVALID)
  * Required: `describe` blocks for hierarchy/states, `it` statements for test cases
  * Forbidden: `()`, `=>`, `{}`, function calls, arrow functions in test descriptions
  * Example: ❌ "Character().created().shouldHaveInitialStats()" (function call syntax)
  * Example: ❌ "describe('Character', () => { it('should have stats') })" (arrow function syntax)

* **Output Format** ⚠️ **Scaffolding Only**
  * Scaffolding generates plain text files: `{test-file-stem}-hierarchy.txt`
  * This is a separate text file from the actual test code file
  * Format: Plain English hierarchy with indentation showing nesting levels
  
  **Example Plain English Scaffold (with domain interactions):**
  ```
  describe Validation
    describe Validation that has been invoked
      describe Scenario 1: Test File Validation
        describe Validation that has been invoked with BDD Validation Command
          describe Validation that is using Specializing Behavior
            it should have selected specialized rule through file pattern matching
            it should have extracted examples from specialized rule
          describe Validation that is using Code-Directed AI Validation
            it should have extracted practice examples from DO/DON'T blocks
            it should have generated checklist from rule sections
  ```
  
  Note: Scaffolding output includes both `describe` blocks (for hierarchy/states) and `it` statements (for test cases). Scaffold uses state-oriented language (nouns, states with linking words).
  
  **Acceptable describe block patterns:**
  * "that has been [past participle]" - completed states (e.g., "that has been created", "that has been invoked")
  * "that is being [verb]" - ongoing states (e.g., "that is being retrieved", "that is using", "that is validating")
  * "that is [adjective/noun]" - current states (e.g., "that is active")
  * "that has [noun]" - possession states (e.g., "that has invalid data")
  * "with [noun]" - context sharing (e.g., "with Epics", "with Features") - connects child to parent context
  * "that have been [past participle]" - plural states (e.g., "that have been added", "that have been removed")
  * "Scenario N: [Description]" - acceptable fallback when state-oriented language is difficult (e.g., "Scenario 1: Test File Validation")
  
  **Context Sharing with "with":**
  When grouping related concepts under a parent, use "with" to connect without requiring direct it statements:
  ```
  describe Story Map File that has changes being arranged    ← Parent state
    describe with Epics                                      ← "with" shares parent context
      describe that have been added                          ← Plural state (Epics that have been added)
        it should have epic folder created
      describe that have been removed                        ← Plural state (Epics that have been removed)
        it should have epic folder archived
    describe with Features                                   ← "with" shares parent context
      describe that have been added                          ← Plural state (Features that have been added)
        it should have feature folder created
  ```
  Note: "with [noun]" describes do NOT require direct it statements - they inherit context from parent and pass to children
  
  **Valid test name patterns:**
  * ✅ "should [verb]" (e.g., "should extract", "should generate", "should validate")
  * ✅ "should [verb] [noun]" (e.g., "should extract epic names", "should display count")
  * ✅ "should have [noun] [past participle]" (e.g., "should have selected", "should have extracted")
  * ✅ "should be [state]" (e.g., "should be valid")
  * ✅ "should have [noun]" (e.g., "should have initial stats")
  
  When domain interactions are present: scenario order determines test ordering (prefer state-oriented describe blocks, but "Scenario N:" format is acceptable fallback), flow steps determine sequence (shown as states like "using Specializing Behavior"), business rules become test cases (state-oriented: "should have selected"), and transformations/lookups provide function hints (state-oriented: "should have extracted", "should have generated").

* **Sample Size** ⚠️ **Scaffolding/Signature**
  * Target approximately 18 describe blocks per scaffold/signature phase
  * Focus on the lowest-level describe blocks and their associated `it` blocks
  * This provides comprehensive coverage without overwhelming scope

**User-Oriented Flow and External State Changes:**

When scaffolding, structure tests around user actions and external state changes, not internal operations:

* **External Triggers First** - Start with what causes the behavior:
  * User actions: "Story Map Generation that has all questions answered"
  * Context state: "Generated Story Map File that has changes"
  * External events: "Epic that has been added to map"

* **Domain State Changes** - Focus on WHAT changed externally:
  * ✅ "Epic that has been added to map" (external change)
  * ✅ "Feature that has been removed from map" (external change)
  * ✅ "Story that has been moved to different feature" (external change)
  * ❌ "Parser that is extracting epics" (internal operation)
  * ❌ "Folder Creator that is creating folders" (internal operation)

* **System Responses** - Then describe what the system does in response:
  * ✅ "Epic that has been added should have folder created"
  * ✅ "Feature that has been removed should have folder archived"
  * ❌ "Folder Generator that is creating folders" (internal focus)

**Temporal Lifecycle Progression:**

When scaffolding domain concepts with lifecycles, follow natural temporal progression:

* **Creation → Usage → Modification → Completion**
  * Example: "Character" → "Character that has been created" → "Character that is being played" → "Character that has been edited" → "Character that has been saved"
* **State Transitions:** Show complete state progression, not isolated states
  * Example: "Attack" → "Attack that has been created" → "Attack that is being prepared" → "Attack that is being executed" → "Attack that has been resolved"

**Complete End-to-End Behaviors:**

Scaffold complete behaviors from start to finish, not fragmented steps:

* ✅ "Character that has been created should have initial stats"
* ✅ "Character that is being played should have experience points tracked"
* ✅ "Character that has been edited should have changes saved"
* ❌ "Character should create" (incomplete - missing context, action-oriented)
* ❌ "Character should play" (incomplete - missing what happens, action-oriented)

**Domain Map Preservation:**

When scaffolding from domain maps, preserve the complete domain map structure (see Section 2 for detailed mapping rules):

* **Primary Validation:** Domain map alignment
  * Scaffold nesting depth must match domain map depth
  * Scaffold concepts must match domain map concepts
  * Scaffold structure must preserve domain map hierarchy
  * No flattening - all nesting levels must be preserved

* **Mapping Rules:**
  * Each domain concept level → corresponding describe block level
  * Domain states → describe blocks with linking words ("that has been", "that is being", "that is", "that has")
    * **Acceptable state patterns:**
      * "that has been [past participle]" - completed states
      * "that is being [verb]" - ongoing states (e.g., "that is being retrieved", "that is being executed", "that is using")
      * "that is [adjective/noun]" - current states
      * "that has [noun]" - possession states
  * Domain behaviors → it blocks ("should ...")
    * **Valid test name patterns:**
      * ✅ "should [verb]" (e.g., "should roll dice", "should validate", "should extract")
      * ✅ "should [verb] [noun]" (e.g., "should calculate damage", "should create folders")
      * ✅ "should have [noun] [past participle]" (e.g., "should have damage calculated")
      * ✅ "should be [state]" (e.g., "should be valid")
      * ✅ "should have [noun]" (e.g., "should have initial stats")
  * Domain sub-concepts → nested describe blocks
  * When domain interaction files (`*-domain-interactions.txt`) are present, you can leverage them to enhance:
    * Business Rules → `it` blocks (each rule becomes a test case)
    * Transformations → function hints for `it` blocks (transformations tell you what object functions will be)
    * Lookups → behavior descriptions for `it` blocks (lookup patterns inform what behaviors to test)

* **Domain Interaction Alignment** (when domain interaction files are present):
  * Scaffold ordering matches scenario order (scenarios provide correct storytelling sequence)
  * Scaffold sequence matches flow step order (flow shows order of domain concept interactions)
  * Business rules have corresponding `it` blocks (each rule covered)
  * Transformations and lookups inform test descriptions (function hints present)

**Validation Checklist for Scaffolding:**

When validating scaffold output, check:

1. ✅ Scaffolding includes `describe` blocks and `it` statements (complete test structure) - plain English for test names, no complex code syntax (`()`, `=>`, `{}`)
2. ✅ **CRITICAL**: Every `describe` block has at least one `it` statement (especially important for `describe` blocks with "that" statements - state blocks MUST have it statements)
3. ✅ Domain map hierarchy preserved (nesting depth matches) AND when domain interaction files are present: domain interaction scenarios aligned (test ordering matches scenario order)
4. ✅ Domain concepts aligned (scaffold concepts match domain map) AND when domain interaction files are present: domain interaction flows aligned (test sequence matches flow step order)
5. ✅ Natural language fluency (reads aloud clearly)
6. ✅ Clear subject in every test name
7. ✅ **User-oriented flow** - Structure around external triggers and state changes, not internal operations
8. ✅ Temporal progression follows lifecycle (if applicable)
9. ✅ Complete end-to-end behaviors (not fragmented) AND when domain interaction files are present: domain interaction business rules covered (each rule has corresponding `it` block)
10. ✅ Sample size appropriate (~18 describe blocks)
11. ✅ When domain interaction files are present: domain interaction transformations/lookups inform test descriptions (function hints present)

**Reference to Core Principles:**

Scaffolding must follow all principles from Section 1 (Business Readable Language) and Section 2 (Fluency, Hierarchy, and Storytelling), with special emphasis on:

* Plain English (Section 1) - especially critical for scaffolding
* Domain language (Section 1) - use domain terms, not technical jargon
* Natural sentences (Section 1) - scaffold should read like stories
* Hierarchy preservation (Section 2) - CRITICAL for domain map mapping
* Storytelling (Section 2) - tests tell stories about domain concepts

## 8. Test Implementation Phase

When implementing tests from signatures (Phase 2: Write Tests), convert empty signatures to full test implementations:

### 8.1 Arrange-Act-Assert Structure

Organize each test with clear structure:
- **Arrange**: Set up test data, mocks, and preconditions
- **Act**: Call the production code under test
- **Assert**: Verify the expected outcomes

This structure makes tests readable and maintainable. Each section has a clear purpose, making it easy to understand what the test does.

### 8.2 Proper Mocking

Mock only at architectural boundaries:
- **DO** mock: External dependencies (file I/O, network calls, databases, APIs)
- **DON'T** mock: Internal classes, business logic, or the code under test
- Extract mock creation to helper functions to reduce duplication

Mocking internal code defeats the purpose of tests. Test your actual business logic by mocking only what's outside your control.

### 8.3 Helper Extraction

Avoid duplication through shared setup:
- Extract duplicate test data creation to factory functions
- Move common setup to shared context (beforeEach/before.each)
- Create reusable helper functions for complex setup
- Keep test bodies focused on the specific behavior being tested

See Section 3 (Balance Context Sharing with Localization) for detailed guidance on helper patterns and shared setup.

### 8.4 Natural Test Failures

Tests call production code directly:
- **DO**: Call production code as it will be used
- **DON'T**: Comment out production code calls
- If production code doesn't exist, tests fail naturally with clear error messages
- This approach shows exactly what needs to be implemented next

Modern BDD approach: write real tests that call real code. If the code doesn't exist yet, the test will fail with a clear message (e.g., "NameError: name 'create_user' is not defined"). This tells you exactly what to implement next.

### 8.5 Signature Conversion

Replace signature markers with full implementations:
- Find tests marked with `# BDD: SIGNATURE` or `// BDD: SIGNATURE`
- Replace empty bodies with Arrange-Act-Assert structure
- Remove signature markers when implementation complete
- Preserve all test structure and hierarchy from signatures
- Work incrementally (~18 describe blocks per iteration)

**Framework-specific examples:** See specializing rules (`bdd-mamba-rule.mdc`, `bdd-jest-rule.mdc`) for concrete syntax examples showing how to convert signatures to full test implementations in your chosen framework.

## 9. Code Implementation Phase

When implementing production code from tests (Phase 3: Write Code), write minimal code to make tests pass:

### 9.1 Minimal Implementation

Implement only what tests demand:
- **DO**: Write simplest code that makes tests pass
- **DON'T**: Add features, abstractions, or complexity not required by tests
- Follow YAGNI (You Aren't Gonna Need It) principle
- If you think "I might need this later" - you don't, the tests will tell you when you do

The tests define the requirements. If there's no test for it, don't implement it.

### 9.2 Make Tests Pass

Focus on making failing tests pass:
- Run tests to identify what's failing
- Implement minimal code to fix failures
- Verify tests pass after implementation
- Don't add extra functionality beyond what tests verify

### 9.3 Avoid Over-Engineering

Keep it simple:
- **DO**: Use simplest data structures and algorithms that work
- **DON'T**: Create elaborate class hierarchies or abstractions prematurely
- Start with simple solutions (e.g., dictionary before custom class)
- Refactor later if tests demand more complexity

Premature abstraction is harder to change than simple code. Let tests drive when complexity is needed.

### 9.4 Check for Regressions

Ensure existing tests still pass:
- Run all tests, not just the new ones
- Verify no regressions introduced
- If regressions occur, fix them before proceeding
- Maintain backwards compatibility

### 9.5 Incremental Implementation

Work in small batches aligned with test scope:
- Implement code for ~18 tests per iteration (matching test implementation scope)
- Verify tests pass after each batch
- Continue until all tests pass
- Keep changes focused and manageable

**Framework-specific examples:** See specializing rules (`bdd-mamba-rule.mdc`, `bdd-jest-rule.mdc`) for concrete syntax examples showing how to implement production code in your chosen framework.

## 10. Use ASCII-Only Characters in Test Code

Test code must use only ASCII characters. Unicode symbols (checkmarks, arrows, emojis, special bullets) cause encoding errors on Windows systems and many CI/CD environments. Use plain text alternatives for test output, assertions, and any string literals in tests.

This principle applies to all test code: scaffolds, signatures, test implementations, and production code that tests interact with. Always use ASCII characters for maximum compatibility across platforms and CI/CD pipelines.

**Framework-specific examples:** See specialized rules (`bdd-mamba-rule.mdc` for Python, `bdd-jest-rule.mdc` for JavaScript) for concrete examples showing unicode errors and ASCII alternatives in each framework.

## Commands

Commands that implement or use this rule:

**Phase-Specific Commands:**
* `/bdd-scaffold` — Generate domain scaffolding (plain English hierarchy) from domain maps
* `/bdd-scaffold-generate` — Generate scaffold hierarchy (delegates to `/bdd-scaffold` generate action)
* `/bdd-scaffold-validate` — Validate scaffold hierarchy (delegates to `/bdd-scaffold` validate action)
* `/bdd-signature` — Generate test signatures (code structure) from scaffolds
* `/bdd-signature-generate` — Generate test signatures (delegates to `/bdd-signature` generate action)
* `/bdd-signature-validate` — Validate test signatures (delegates to `/bdd-signature` validate action)
* `/bdd-test` — Implement test code from signatures
* `/bdd-test-generate` — Implement test code (delegates to `/bdd-test` generate action)
* `/bdd-test-validate` — Validate test implementations (delegates to `/bdd-test` validate action)
* `/bdd-code` — Implement production code to make tests pass
* `/bdd-code-generate` — Implement production code (delegates to `/bdd-code` generate action)
* `/bdd-code-validate` — Validate production code (delegates to `/bdd-code` validate action)

**Workflow Orchestrator Commands:**
* `/bdd-workflow` — Lightweight orchestrator that delegates to appropriate phase-specific commands (Domain Scaffold, Signatures, Write Tests, Write Code)
* `/bdd-workflow-generate` — Generate workflow phase output (delegates to `/bdd-workflow` generate action)
* `/bdd-workflow-validate` — Validate workflow phase output (delegates to `/bdd-workflow` validate action)

**Note**: Workflow orchestrator commands are VERY LIGHTWEIGHT and VERY SMALL - they simply delegate to the right phase-specific command to do its job. They do NOT contain complex logic or duplicate phase command functionality.

**General Validation:**
* `/bdd-validate` — Validate BDD test files against these principles

## Executing Commands
* /bdd-bdd-code — Implement production code to make tests pass following BDD principles

* /bdd-bdd-test — Implement test code from signatures following BDD principles
