---
description: BDD testing practices for Mamba/Python
globs: ["**/*test*.py", "**/*_test.py", "**/test_*.py", "**/*spec*.py"]
alwaysApply: false
---
**When** practicing BDD testing with Mamba/Python,
**then** follow these Mamba-specific patterns.

This rule extends `bdd-rule.mdc` â€” all base BDD principles apply throughout.

**Executing Commands:**
* `/bdd-validate` â€” Validate BDD test files against these principles
* `/bdd-workflow` â€” Execute BDD workflow phases (Domain Scaffold, Signatures, Write Tests, Write Code)

## Conventions

Naming conventions, file locations, and structural conventions for Mamba/Python BDD tests (what the rules apply to, not the rule files themselves).

* Test file naming: Use `*test*.py`, `*_test.py`, `test_*.py`, or `*spec*.py` patterns
* Test file location: Place test files alongside source code or in dedicated test directories following Python/Mamba conventions
* Framework syntax: Use Mamba framework syntax: `with description()`, `with context()`, `with it()`, `with before.each`
* Code examples: Use Python syntax with Mamba-specific patterns

## 1. Business Readable Language

Write `description`/`context`/`it` so that inner/outer sentences create natural sentence. Use nouns for `description` (concepts, states). Start each `it()` with "should â€¦". Nest from broad â†’ specific; each child adds context. Use plain behavioral language. Prefer domain terms over technical jargon. Connect base business concept to more specific concepts using linking words: "that is/that has" "that has been"

**[DO]:**
* Use `with description()` for top-level concepts
* Use `with context()` for nested contexts that add detail
* Use `with it()` for individual behaviors
* Create natural sentences when reading description â†’ context â†’ it
* Use linking words like "that is", "that has", "that has been" to connect concepts

```python
with description('a ranged damage power'):
    with context('that has targeted and resulted in a successful attack'):
        with it('should apply damage based on degrees of failure'):
            expect(result.injuries).to(equal(2))
```

**[DON'T]:**
* Use verbs for description blocks
* Omit "should" from it() blocks
* Use technical jargon or class names
* Flatten hierarchy unnecessarily
* Use implementation-focused language

```python
with description('when attacking Target'):
with description('Power.execute()'):
with context('retrieved attack'):
with it('sets is_submitting flag'):
```

## 2. Comprehensive and Brief

Test observable behavior, not hidden internals. Cover state, validation, rules, and interactions. Cover normal, edge, and failure paths. Keep tests short, expressive, readable. Keep tests independent, deterministic, and fast.

**[DO]:**
* Test observable outcomes and state changes
* Use `expect()` assertions for clear expectations
* Set up test data in `with before.each` blocks
* Write focused tests for each distinct behavior
* Keep test bodies concise and readable

```python
with description('a damage power'):
    with before.each:
        self.mock_target = {'dodge': 15, 'injury': 0}
    
    with it('should be a ranged attack'):
        expect(attack.is_ranged).to(equal(True))
    
    with it('should calculate DC from targets dodge'):
        expect(attack.execute(self.mock_target).DC).to(equal(20))
```

**[DON'T]:**
* Test internal methods or private attributes
* Assert on mock internals or framework internals
* Write overly broad tests
* Create tests that depend on execution order
* Access implementation details

```python
with it('calls _validate()'):
    expect(form._flag).to(be_true)
    expect(form._validate).to(have_been_called)
with it('handles attack'):
```

## 3. Balance Context Sharing with Localization

Nest parent context, don't repeat it. Provide expected data via helper factories/builders. Extract complex logic into helpers. Reuse helpers/factories where possible. **Note:** Mamba does NOT support moving `before.each` to parent `describe` blocks. Extract duplicate setup to a helper function and call it in each test.

**[DO]:**
* Create helper functions for common setup
* Use factory functions for creating test data
* Call helper functions in each test that needs them
* Extract complex setup logic into reusable helpers
* Use `with before.each` for setup shared within a single context

```python
def create_power(o=None):
    return Power({**{'name': 'Test', 'rank': 10}, **(o or {})})

with description('a Power'):
    with before.each:
        self.factory = MockFactory()
        self.factory.reset()
        self.power = create_power()
```

**[DON'T]:**
* Duplicate setup code across sibling tests
* Repeat parent context setup unnecessarily
* Try to move `before.each` to parent contexts (Mamba limitation)
* Create overly complex setup in individual tests
* Mix shared and test-specific setup without clear separation

```python
with description('Power'):
    with context('created from actor'):
        with before.each:
            self.actor = {'id': '123'}
    with context('that is ranged'):
        with before.each:
            self.actor = {'id': '123'}  # Duplicate setup
```

## 4. Cover All Layers of the System

Include separate front end, business logic, integration, and data access tests. Isolate across architecture boundaries with mocks and stubs.

**[DO]:**
* Write separate test files for each architectural layer
* Use `unittest.mock` or `mamba` mocks to isolate layers
* Test business logic independently of data access
* Create integration tests for cross-layer behavior
* Use appropriate mocking strategies for each layer

**[DON'T]:**
* Mix concerns from different layers in the same test
* Test dependencies instead of the code under test
* Create tests that require multiple layers to be running
* Over-mock to the point where tests don't verify real behavior
* Skip testing important layers

## 5. Unit Tests the Front-End

Mock services, business logic, and routing. Stub user events and verify resulting state or view. Test user-visible behavior, not internal component state or methods.

**[DO]:**
* Mock backend services and business logic
* Test user-visible outcomes and interactions
* Verify context data and view state
* Focus on what users see and experience
* Use mocks to isolate front-end from backend

```python
with description('an attack power display'):
    with before.each:
        self.mock_service = Mock()
        self.context = prepare_context(self.actor)
    
    with it('should include attack bonus in context'):
        expect(self.context['attack_powers'][0]['bonus']).to(equal(8))
```

**[DON'T]:**
* Test internal component state or methods
* Assert on HTML rendering details
* Make real HTTP requests in unit tests
* Access component internals directly
* Test framework internals or implementation details

```python
with it('renders bonus'):
    expect(html).to(contain('value="8"'))
    expect(html).to(contain('color: blue'))
    requests.get('http://api.com')
with it('calls _on_mount()'):
    expect(component._on_mount).to(have_been_called)
```

## 6. Signature Phase Requirements

When creating test signatures (Phase 1: Build Test Signatures), generate test structure with empty bodies:

**[DO]:**
* Use proper Mamba syntax: `with description()`, `with context()`, `with it()`
* Keep test bodies empty with only `pass` statement
* Mark each test with `# BDD: SIGNATURE` comment at start of body
* Preserve ALL nesting levels from scaffold hierarchy
* Convert plain English scaffold to proper code syntax
* Update test file directly (e.g., `test_zorbling.py`)
* Target ~18 describe blocks per signature iteration

```python
# From scaffold (plain English):
# Zorbling Management
#   Creating Zorblings
#     should create zorbling with valid data
#     should reject zorbling with invalid data

# To signature (code structure):
with description("Zorbling Management"):
    with context("Creating Zorblings"):
        with it("should create zorbling with valid data"):
            # BDD: SIGNATURE
            pass
        
        with it("should reject zorbling with invalid data"):
            # BDD: SIGNATURE
            pass
```

**[DON'T]:**
* Add mocks, stubs, or helpers in signature phase
* Include implementation code or assertions
* Flatten hierarchy from scaffold
* Skip signature markers
* Change nesting structure from scaffold

```python
# Missing signature marker
with it("should create zorbling"):
    pass

# Has implementation code (wrong for signature phase)
with it("should create zorbling"):
    zorbling = Zorbling()
    expect(zorbling).not_to(be_none)
```

## 7. Test Implementation Phase Examples

When implementing tests from signatures (Phase 2: Write Tests), follow base rule Â§ 8 principles with Mamba-specific syntax:

**[DO]:**
* Use Arrange-Act-Assert structure with Python syntax
* Mock using `unittest.mock` or `mamba` mocks for external boundaries only
* Extract setup to helper functions or `with before.each`
* Call production code directly - let tests fail naturally if code doesn't exist
* Replace `# BDD: SIGNATURE` markers with full implementation

```python
# From signature:
with it("should create user with valid email"):
    # BDD: SIGNATURE
    pass

# To full test implementation:
with it("should create user with valid email"):
    # Arrange
    email = "test@example.com"
    user_data = {"email": email, "name": "Test User"}
    
    # Act
    user = create_user(user_data)
    
    # Assert
    expect(user.email).to(equal(email))
    expect(user.is_active).to(be_true)
```

**[DON'T]:**
* Comment out production code calls
* Mock internal business logic
* Duplicate setup across sibling tests

```python
# DON'T: Commented out code
with it("should create user"):
    # email = "test@example.com"
    # user = create_user({"email": email})
    pass

# DON'T: Mocking internal business logic
with it("should validate user"):
    mock_user = Mock()  # Don't mock the thing you're testing
    expect(mock_user.is_valid()).to(be_true)
```

## 8. Code Implementation Phase Examples

When implementing production code from tests (Phase 3: Write Code), follow base rule Â§ 9 principles with Python-specific syntax:

**[DO]:**
* Implement minimal Python code to make tests pass
* Use simple data structures (dict, list) before creating classes
* Follow Python conventions (PEP 8)
* Return what tests expect, nothing more
* Let tests drive when you need classes or complexity

```python
# Test expects:
with it("should create user with valid email"):
    user = create_user({"email": "test@example.com", "name": "Test"})
    expect(user["email"]).to(equal("test@example.com"))
    expect(user["is_active"]).to(be_true)

# Minimal implementation (start with dict):
def create_user(user_data):
    """Create user with validated data"""
    email = user_data.get("email")
    if not email or "@" not in email:
        raise ValueError("Invalid email format")
    
    return {
        "email": email,
        "name": user_data.get("name"),
        "role": user_data.get("role", "user"),
        "is_active": True
    }
```

**[DON'T]:**
* Add features not tested
* Create complex class hierarchies prematurely
* Add configuration or options not tested

```python
# DON'T: Over-engineered with untested features
class User:
    def __init__(self, email, name, role="user", permissions=None, preferences=None):
        self.email = email
        self.name = name
        self.role = role
        self.permissions = permissions or []  # Not tested
        self.preferences = preferences or {}  # Not tested
        self.created_at = datetime.now()      # Not tested
    
    def validate_permissions(self):  # Not tested
        pass
    
    def update_preferences(self, prefs):  # Not tested
        pass
```

## 10. Use ASCII-Only Characters in Test Code

**[DO]:**
Use plain ASCII text that works on all systems:
```python
print("PASS: Test passed")
print("SUCCESS: All assertions correct")
print("Next step:")
expect(result).to(contain("correct the error"))
# Describe emojis in comments if needed for clarity
# EPIC Create Character, FEATURE Establish Identity, STORY User enters name
```

**[DON'T]:**
Unicode characters crash on Windows console:
```python
print("âœ“ Test passed")  # Unicode checkmark
print("âœ… All assertions correct")  # Emoji checkmark
print("â†’ Next step")  # Unicode arrow
expect(result).to(contain("â†’"))  # Unicode in assertion

# Emojis in test data/strings cause encoding errors
story_map_content = """ğŸ¯ **Create Character**
âš™ï¸ **Establish Identity**  
ğŸ“ User enters name"""  # FAILS on Windows
```

**Error:** `UnicodeEncodeError: 'charmap' codec can't encode character '\u2713' in position 0`

**Validation:** The BDDUnicodeHeuristic detects ALL non-ASCII characters (ord > 127) including:
- Unicode symbols: âœ“, âœ…, âŒ, â†’, â€¢, etc.
- Emojis: ğŸ¯, âš™ï¸, ğŸ“, ğŸ”¥, etc.
- Tree characters: â”‚, â”œ, â””, â”€
- Accented letters: Ã©, Ã±, Ã¼, etc.

Use ASCII alternatives: EPIC, FEATURE, STORY, PASS, FAIL, ERROR, or describe in comments.

## Commands

Commands that implement or use this rule:

* `/bdd-validate` â€” Validate BDD test files against these principles
* `/bdd-workflow` â€” Execute BDD workflow phases (Domain Scaffold, Signatures, Write Tests, Write Code)
* `/bdd-scaffold` â€” Generate domain scaffolding (plain English hierarchy) from domain maps
* `/bdd-signature` â€” Generate test signatures (code structure) from scaffolds
* `/bdd-test` â€” Implement test code from signatures
* `/bdd-code` â€” Implement production code to make tests pass
