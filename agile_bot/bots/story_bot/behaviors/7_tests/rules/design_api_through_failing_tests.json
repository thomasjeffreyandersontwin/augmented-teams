{
  "description": "Write tests against the REAL expected API (not dummy variables or placeholders) BEFORE implementing code. Tests MUST fail initially because the API doesn't exist yet. This failure reveals the complete API design including parameter objects, config setup, dependencies, and return values. Set up real test data (files, directories, objects) and call the real API. Only mock I/O boundaries (file access, network, database) and only when explicitly necessary. The failing test serves as executable API documentation.",
  "examples": [
    {
      "do": {
        "description": "Write test against real expected API that fails",
        "content": [
          "def test_project_initializes_with_agent_config(self, tmp_path):",
          "    \"\"\"Project initializes by loading agent configuration from file.\"\"\"",
          "    # Given: Real test workspace with config file",
          "    project_path = tmp_path / 'projects' / 'test-project'",
          "    project_path.mkdir(parents=True, exist_ok=True)",
          "    ",
          "    agent_config_path = tmp_path / 'agents' / 'base' / 'agent.json'",
          "    agent_config_path.parent.mkdir(parents=True, exist_ok=True)",
          "    agent_config_path.write_text(json.dumps({",
          "        'name': 'story_bot',",
          "        'behaviors': ['shape', 'discovery']",
          "    }))",
          "    ",
          "    # When: Call REAL expected API (doesn't exist yet!)",
          "    project = Project(",
          "        project_path=project_path,",
          "        agent_config_path=agent_config_path,",
          "        workspace_root=tmp_path",
          "    )",
          "    project.initialize()",
          "    ",
          "    # Then: Verify real behavior",
          "    assert project.agent.name == 'story_bot'",
          "    assert project.agent.behaviors == ['shape', 'discovery']",
          "    assert project.is_initialized is True",
          "    ",
          "    # TEST FAILS: AttributeError - Project doesn't have 'initialize' method",
          "    # GOOD! Now we know:",
          "    # - Project needs __init__ with project_path, agent_config_path, workspace_root",
          "    # - Project needs initialize() method",
          "    # - Project needs agent property",
          "    # - Project needs is_initialized property",
          "    # - Agent needs name and behaviors attributes"
        ]
      },
      "dont": {
        "description": "Use dummy variables or placeholders to make test pass",
        "content": [
          "def test_project_initializes():",
          "    # DON'T: Use dummy/placeholder values",
          "    project = None  # Placeholder - hides real API!",
          "    agent = None    # Placeholder - hides real API!",
          "    ",
          "    # Test passes but reveals NOTHING about real API",
          "    assert project is None  # USELESS!",
          "    assert agent is None    # USELESS!",
          "    ",
          "    # WRONG: This doesn't show:",
          "    # - What parameters Project needs",
          "    # - What methods Project should have",
          "    # - What the Agent structure looks like",
          "    # - How initialization works"
        ]
      }
    },
    {
      "do": {
        "description": "Set up real test data, call real API, let it fail",
        "content": [
          "def test_workflow_executes_behavior_sequence(self, tmp_path):",
          "    \"\"\"Workflow executes behaviors in configured sequence.\"\"\"",
          "    # Given: Real agent with real config",
          "    agent_path = tmp_path / 'agents' / 'story_bot'",
          "    agent_path.mkdir(parents=True, exist_ok=True)",
          "    ",
          "    config = {",
          "        'name': 'story_bot',",
          "        'behaviors': [",
          "            {'name': 'shape', 'order': 1},",
          "            {'name': 'discovery', 'order': 2}",
          "        ]",
          "    }",
          "    (agent_path / 'agent.json').write_text(json.dumps(config))",
          "    ",
          "    # When: Create real objects and call real API",
          "    agent = Agent.load_from_path(agent_path)",
          "    workflow = Workflow(agent=agent, workspace=tmp_path)",
          "    result = workflow.execute_next_behavior()",
          "    ",
          "    # Then: Verify real behavior",
          "    assert result.behavior_name == 'shape'",
          "    assert result.status == 'completed'",
          "    assert workflow.current_behavior_index == 1",
          "    ",
          "    # TEST FAILS: AttributeError - Agent.load_from_path doesn't exist",
          "    # GOOD! Failure shows exact API needed:",
          "    # - Agent.load_from_path(path) class method",
          "    # - Workflow.__init__(agent, workspace) constructor",
          "    # - Workflow.execute_next_behavior() method returns result object",
          "    # - Result object with behavior_name, status properties",
          "    # - Workflow.current_behavior_index property"
        ]
      },
      "dont": {
        "description": "Mock everything or use fake objects",
        "content": [
          "def test_workflow_executes():",
          "    # DON'T: Mock internal objects that should be real",
          "    mock_agent = Mock()",
          "    mock_agent.name = 'story_bot'",
          "    ",
          "    mock_workflow = Mock()",
          "    mock_workflow.execute_next_behavior.return_value = Mock(status='completed')",
          "    ",
          "    # Test passes but reveals NOTHING",
          "    result = mock_workflow.execute_next_behavior()",
          "    assert result.status == 'completed'",
          "    ",
          "    # WRONG: Doesn't show:",
          "    # - How Agent is constructed",
          "    # - How Workflow is constructed",
          "    # - What parameters they need",
          "    # - What the real implementation does"
        ]
      }
    },
    {
      "do": {
        "description": "Mock only I/O boundaries when explicitly necessary",
        "content": [
          "def test_agent_fetches_remote_template(self, tmp_path):",
          "    \"\"\"Agent fetches template from remote URL.\"\"\"",
          "    # Given: Real agent setup",
          "    agent_path = tmp_path / 'agents' / 'story_bot'",
          "    agent_path.mkdir(parents=True, exist_ok=True)",
          "    ",
          "    # Mock ONLY the network I/O boundary (can't control external API)",
          "    with patch('requests.get') as mock_get:",
          "        mock_get.return_value.text = '# Template content'",
          "        mock_get.return_value.status_code = 200",
          "        ",
          "        # When: Call REAL Agent API",
          "        agent = Agent(name='story_bot', workspace=agent_path)",
          "        template = agent.fetch_remote_template(",
          "            url='https://example.com/template.md',",
          "            cache_path=agent_path / 'templates'",
          "        )",
          "        ",
          "        # Then: Verify real behavior",
          "        assert template.content == '# Template content'",
          "        assert (agent_path / 'templates' / 'template.md').exists()",
          "        mock_get.assert_called_once_with('https://example.com/template.md')",
          "    ",
          "    # TEST FAILS: Agent.fetch_remote_template doesn't exist",
          "    # GOOD! Shows API needs:",
          "    # - Agent.__init__(name, workspace)",
          "    # - Agent.fetch_remote_template(url, cache_path) method",
          "    # - Returns template object with content property",
          "    # - Caches to local file",
          "    # Only network call is mocked - everything else is real!"
        ]
      },
      "dont": {
        "description": "Mock file operations that can use real temp files",
        "content": [
          "def test_agent_caches_template():",
          "    # DON'T: Mock file operations",
          "    with patch('pathlib.Path.exists') as mock_exists:",
          "        with patch('pathlib.Path.mkdir') as mock_mkdir:",
          "            with patch('pathlib.Path.write_text') as mock_write:",
          "                mock_exists.return_value = False",
          "                ",
          "                agent = Agent('story_bot', Path('/fake'))",
          "                agent.cache_template('content', 'template.md')",
          "                ",
          "                mock_mkdir.assert_called_once()",
          "                mock_write.assert_called_once()",
          "    ",
          "    # WRONG: Use real tmp_path and real file operations!",
          "    # File I/O is controllable and testable without mocking"
        ]
      }
    },
    {
      "do": {
        "description": "Design complex APIs through failing tests with real objects",
        "content": [
          "def test_behavior_runner_executes_multi_step_workflow(self, tmp_path):",
          "    \"\"\"BehaviorRunner executes multi-step workflow with state tracking.\"\"\"",
          "    # Given: Real test workspace with config",
          "    workspace = tmp_path / 'test-workspace'",
          "    workspace.mkdir()",
          "    ",
          "    config = WorkflowConfig(",
          "        steps=[",
          "            StepConfig(name='gather_context', timeout=30),",
          "            StepConfig(name='build_knowledge', timeout=60),",
          "            StepConfig(name='render_output', timeout=45)",
          "        ],",
          "        workspace_path=workspace",
          "    )",
          "    ",
          "    state = WorkflowState(",
          "        current_step=0,",
          "        completed_steps=[],",
          "        workspace=workspace",
          "    )",
          "    ",
          "    # When: Execute real workflow",
          "    runner = BehaviorRunner(config=config, initial_state=state)",
          "    result = runner.execute_all_steps()",
          "    ",
          "    # Then: Verify state tracking",
          "    assert result.total_steps == 3",
          "    assert result.completed_steps == ['gather_context', 'build_knowledge', 'render_output']",
          "    assert result.final_state.current_step == 3",
          "    assert (workspace / 'workflow_state.json').exists()",
          "    ",
          "    # TEST FAILS: Multiple failures reveal complete API:",
          "    # - WorkflowConfig class with steps list and workspace_path",
          "    # - StepConfig class with name and timeout",
          "    # - WorkflowState class with current_step, completed_steps, workspace",
          "    # - BehaviorRunner.__init__(config, initial_state)",
          "    # - BehaviorRunner.execute_all_steps() returns result",
          "    # - Result object with total_steps, completed_steps, final_state",
          "    # - State persisted to workflow_state.json",
          "    # Complete API design visible through test!"
        ]
      },
      "dont": {
        "description": "Build up API incrementally with dummy values",
        "content": [
          "def test_behavior_runner():",
          "    # DON'T: Start with dummies and build up slowly",
          "    runner = None  # Placeholder",
          "    assert runner is None",
          "    ",
          "    # Later...",
          "    runner = BehaviorRunner()  # Empty constructor",
          "    assert runner is not None",
          "    ",
          "    # Later...",
          "    result = runner.execute()  # Simplified, not real API",
          "    assert result == 'done'",
          "    ",
          "    # WRONG: Should design complete API upfront through test:",
          "    # - What parameters does runner need?",
          "    # - What configuration?",
          "    # - What state tracking?",
          "    # - What does result look like?",
          "    # Write test with COMPLETE expected API!"
        ]
      }
    }
  ],
  "rationale": [
    "Failing tests against real API reveal complete design including parameters, config, dependencies, and return types",
    "Test serves as executable documentation of expected API before implementation exists",
    "Real test data (files, objects) shows how production code will actually be used",
    "Avoiding mocks for internal objects ensures API is testable and well-designed",
    "Seeing the test fail validates that test is testing something real, not dummy values",
    "Forces thinking about API usability and design before writing implementation",
    "Real setup code shows what dependencies and configuration production code needs",
    "Parameter objects and config structures become visible through test construction"
  ],
  "key_principles": [
    "Write tests against REAL expected API (not dummy/placeholder values)",
    "Tests MUST fail initially - this validates the test and reveals the API",
    "Set up real test data using tmp_path (files, directories, config)",
    "Call real constructors and methods with real parameters",
    "Only mock I/O boundaries (network, external APIs) when explicitly necessary",
    "Never mock file operations - use real temp files",
    "Never mock internal objects - use real implementations",
    "Test should show complete API: parameters, config, dependencies, return types",
    "Failing test is executable API documentation",
    "Design is revealed through test structure, not implementation"
  ],
  "antipatterns": [
    "Using None or placeholder values instead of real API calls",
    "Making tests pass with dummy assertions like 'assert x is None'",
    "Mocking file operations when tmp_path provides real files",
    "Mocking internal objects that should be real implementations",
    "Building up API incrementally with partial/incomplete tests",
    "Writing tests that pass without real implementation (false positives)",
    "Hiding API design by not showing real parameters and config",
    "Using simplified APIs in tests that don't match real usage"
  ]
}


